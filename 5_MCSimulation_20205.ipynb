{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samwong3333/try/blob/main/5_MCSimulation_20205.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2WxY2h7Uz8D",
        "outputId": "87fbb688-e163-49d7-9e7d-f16a91871b9c"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "mount failed",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b7c4692ea6c9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# change directory from google colab into google drive, connect to google drive first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "# change directory from google colab into google drive, connect to google drive first\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IXd8gxizVDt5"
      },
      "outputs": [],
      "source": [
        "# change the present working directory\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/RMSC6007')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5OgjHh8lBull"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "from pandas.errors import SettingWithCopyWarning\n",
        "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
        "\n",
        "# feel free to modify, for example, change the context to \"notebook\"\n",
        "sns.set_theme(context=\"talk\", style=\"whitegrid\",\n",
        "              palette=\"colorblind\", color_codes=True,\n",
        "              rc={\"figure.figsize\": [12, 8]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XcN8ft6CBulo"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlWOn6Q7Bulo"
      },
      "source": [
        "# Chapter 6: Monte Carlo simulations in finance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvJRZ-dKBulp"
      },
      "source": [
        "Monte Carlo simulations are a class of computational algorithms that use repeated random sampling to solve any problems that have a probabilistic interpretation. In finance, one of the reasons they gained popularity is that they can be used to accurately estimate integrals. The main idea of Monte Carlo simulations is to produce a multitude of sample paths—possible scenarios/outcomes, often over a given period of time. The horizon is then split into a specified number of time steps and the process of doing so is called **discretization**. Its goal is to approximate continuous time, since the pricing of financial instruments happens in continuous time.\n",
        "\n",
        "The results from all these simulated sample paths can be used to calculate metrics such as the percentage of times an event occurred, the average value of an instrument at the last step, and so on. Historically, the main problem with the Monte Carlo approach was that it required heavy computational power to calculate all possible scenarios. Nowadays, it is becoming less of a problem as we can run fairly advanced simulations on a desktop computer or a laptop.\n",
        "\n",
        "By the end of this chapter, we will have seen how we can use Monte Carlo methods in various scenarios and tasks. In some of them, we will create the simulations from scratch, while in others, we will use modern Python libraries to make the process even easier. Due to the method's flexibility, Monte Carlo is one of the most important techniques in computational finance. It can be adapted to various problems, such as pricing derivatives with no closed-form solution (American/Exotic options), valuating bonds (for example, a zero-coupon bond), estimating the uncertainty of a portfolio (for example, by calculating Value-at-Risk and Expected Shortfall), or carrying out stress-tests in risk management. We show how to solve some of these problems in this chapter.\n",
        "\n",
        "In this chapter, we cover the following recipes:\n",
        "\n",
        "* Simulating stock price dynamics using Geometric Brownian Motion\n",
        "* Pricing European options using simulations\n",
        "* Pricing American options with Least Squares Monte Carlo\n",
        "* Pricing American options using Quantlib\n",
        "* Estimating value-at-risk using Monte Carlo\n",
        "\n",
        "See also: https://www.ibm.com/cloud/learn/monte-carlo-simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXgT3AvBBulq"
      },
      "source": [
        "## Simulating stock price dynamics using Geometric Brownian Motion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH49amceBulq"
      },
      "source": [
        "Thanks to the unpredictability of financial markets, simulating stock prices plays an important role in the valuation of many derivatives, such as options. Due to the aforementioned randomness in price movement, these simulations rely on **stochastic differential equations (SDE)**.\n",
        "\n",
        "A stochastic process is said to follow the **Geometric Brownian Motion (GBM)** when it satisfies the following SDE:\n",
        "\n",
        "<center>$dS_t= \\mu S_tdt + \\sigma S_tdW_t $</center>\n",
        "\n",
        "Here, we have the following:\n",
        "\n",
        "* $S_t$: Stock price\n",
        "* $\\mu$: The drift coefficient, that is, the average return over a given period or the instantaneous expected return\n",
        "* $\\sigma$: The diffusion coefficient, that is, how much volatility is in the drift\n",
        "* $W_t$: The Brownian Motion\n",
        "\n",
        "We will not investigate the properties of the Brownian Motion in too much depth, as it is outside the scope of this book. Suffice to say, Brownian increments are calculated as a product of a Standard Normal random variable $(rv ∼ N(0,1))$ and the square root of the time increment. Another way to say this is that the Brownian increment comes from $rv ∼ N(0,t)$, where $t$ is the time increment. We obtain the Brownian path by taking the cumulative sum of the Brownian increments.\n",
        "\n",
        "The SDE has a closed-form solution (only a few SDEs have it):\n",
        "<center>$S(t)=S_0\\exp\\{(\\mu-\\frac{1}{2}\\sigma^2)t+\\sigma W_t\\}$</center>\n",
        "\n",
        "Here, $S_0=S(0)$ is the initial value of the process, which in this case is the initial price of a stock. The preceding equation presents the relationship compared to the initial stock price.\n",
        "\n",
        "For simulations, we can use the following recursive formula:\n",
        "\n",
        "<center>$S(t_{i+1})=S(t_i)\\exp[(\\mu-\\frac{1}{2}\\sigma^2)(t_{i+1}-t_i)+\\sigma \\sqrt{t_{i+1}-t_i}Z_{i+1}]$</center>\n",
        "\n",
        "Here, $Z_i$ is a Standard Normal random variable and $i=0,...T-1$ is the time index. This specification is possible because the increments of W are independent and normally distributed.\n",
        "\n",
        "GBM is a process that does not account for mean-reversion and time-dependent volatility. That is why it is often used for stocks and not for bond prices, which tend to display long-term reversion to the face value.\n",
        "\n",
        "In this recipe, we use Monte Carlo methods and the Geometric Brownian Motion to simulate Microsoft's stock prices one month ahead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0NrUn_6Bulr"
      },
      "source": [
        "### How to do it..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcKcf72UBulr"
      },
      "source": [
        "1. Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O3SCARb3CDpk"
      },
      "outputs": [],
      "source": [
        "pip install yfinance;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tbdpnP4pBuls"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNLLf7CcBuls"
      },
      "source": [
        "2. Define parameters for downloading data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VXP9e3dIBult"
      },
      "outputs": [],
      "source": [
        "RISKY_ASSET = 'MSFT'\n",
        "START_DATE = '2019-01-01'\n",
        "END_DATE = '2019-07-31'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-MErn3dBult"
      },
      "source": [
        "3. Download data from Yahoo Finance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9_x_YhLGBult"
      },
      "outputs": [],
      "source": [
        "df = yf.download(RISKY_ASSET, start=START_DATE,\n",
        "                 end=END_DATE)\n",
        "\n",
        "print(f'Downloaded {df.shape[0]} rows of data.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEck2KTkBulu"
      },
      "source": [
        "4. Calculate daily returns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fz9n1BrgBulu",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "adj_close = df['Close']\n",
        "returns = adj_close.pct_change().dropna()\n",
        "\n",
        "ax = returns.plot()\n",
        "ax.set_title(f'{RISKY_ASSET} returns: {START_DATE} - {END_DATE}',\n",
        "             fontsize=16)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'Average return:', round(100 * returns['MSFT'].mean(), 2), '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ct4FuoZ7VXGd"
      },
      "outputs": [],
      "source": [
        "returns.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ykoXmHYBulu"
      },
      "source": [
        "5. Split data into the training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h1-qySrFBulu"
      },
      "outputs": [],
      "source": [
        "train = returns['2019-01-01':'2019-06-30']\n",
        "test = returns['2019-07-01':'2019-07-31']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAtiPzgLBulv"
      },
      "source": [
        "6. Specify the parameters of the simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gVWLWAs3XdZV"
      },
      "outputs": [],
      "source": [
        "adj_close.loc[train.index[-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Mpa9FkY6Bulv"
      },
      "outputs": [],
      "source": [
        "T = len(test) # T: Forecasting horizon\n",
        "N = len(test) # N: Number of time increments in the forecasting horizon\n",
        "S_0 = adj_close['MSFT'].loc[train.index[-1]] # S_0: Initial price, the last observation from the training set\n",
        "N_SIM = 100 # Number of simulated paths\n",
        "mu = train['MSFT'].mean()\n",
        "sigma = train['MSFT'].std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vrLDjIXuY8X9"
      },
      "outputs": [],
      "source": [
        "sigma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTYclhWjBulv"
      },
      "source": [
        "7. Define the function used for simulations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HVPnzEYXBulv"
      },
      "outputs": [],
      "source": [
        "def simulate_gbm(s_0, mu, sigma, n_sims, T, N,\n",
        "                 random_seed=42):\n",
        "    '''\n",
        "    Function used for simulating stock returns using Geometric Brownian Motion.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    s_0 : float\n",
        "        Initial stock price\n",
        "    mu : float\n",
        "        Drift coefficient\n",
        "    sigma : float\n",
        "        Diffusion coefficient\n",
        "    n_sims : int\n",
        "        Number of simulations paths\n",
        "    dt : float\n",
        "        Time increment, most commonly a day\n",
        "    T : float\n",
        "        Length of the forecast horizon, same unit as dt\n",
        "    N : int\n",
        "        Number of time increments in the forecast horizon\n",
        "    random_seed : int\n",
        "        Random seed for reproducibility\n",
        "\n",
        "    Returns\n",
        "    -----------\n",
        "    S_t : np.ndarray\n",
        "        Matrix (size: n_sims x (T+1)) containing the simulation results.\n",
        "        Rows respresent sample paths, while columns point of time.\n",
        "    '''\n",
        "    # set seed for reproducible results\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    # time increment\n",
        "    dt = T/N\n",
        "    # Brownian increments (the matrix of increments, each row describes one sample path)\n",
        "    dW = np.random.normal(scale = np.sqrt(dt), size=(n_sims, N))\n",
        "    # calculate the cumulative sum of the Brownian increments\n",
        "    W = np.cumsum(dW, axis=1)\n",
        "\n",
        "    # generate a sequence of N numbers evenly spaced from dt to T\n",
        "    time_step = np.linspace(dt, T, N)\n",
        "\n",
        "    # broadcast the array `time_step` to a new shape (n_sims dimensions and each with N elements)\n",
        "    time_steps = np.broadcast_to(time_step, (n_sims, N))\n",
        "\n",
        "    # calculate the stock price at time t using the closed-form formula\n",
        "    S_t = s_0 * np.exp((mu - 0.5 * sigma**2) * time_steps\n",
        "                       + sigma * W)\n",
        "    # add the initial stock price as the first element in each demension of `S_t`\n",
        "    S_t = np.insert(S_t, 0, s_0, axis=1)\n",
        "\n",
        "    return S_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bues0dKWBulv"
      },
      "source": [
        "Remarks:\n",
        "* For reproducible results, use `np.random.seed` before simulating the paths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVirncyHBulv"
      },
      "source": [
        "Notes:\n",
        "* Random Numbers in NumPy\n",
        "    * NumPy offers the `random` module to work with random numbers.\n",
        "    * `numpy.random.normal(loc=0.0, scale=1.0, size=None)`\n",
        "        * Draw random samples from a normal (Gaussian) distribution.\n",
        "        * `size`: *int or tuple of ints, optional*. Output shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JoBDBHtYBulw"
      },
      "outputs": [],
      "source": [
        "np.random.normal(size=(2, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpfYxdNhBulw"
      },
      "source": [
        "Notes:\n",
        "* `numpy.broadcast_to(array, shape)`\n",
        "    * Broadcast an array to a new shape.\n",
        "    * Raises: ValueError - If the array is not compatible with the new shape according to NumPy’s broadcasting rules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kcbHmKDkBulw",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "a=np.arange(4)\n",
        "print(a)\n",
        "print(a.reshape(4,1)) # reshape() is a method for ndarray\n",
        "np.broadcast_to(a,(6,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DkwkB9w5W5Cg"
      },
      "outputs": [],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JwKdVCSpBulw",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# not compatible according to NumPy’s broadcasting rules\n",
        "#np.broadcast_to(a,(4,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "voqXuK9MBulw"
      },
      "outputs": [],
      "source": [
        "np.broadcast_to(a,(2,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7Ee1eEqBulw"
      },
      "source": [
        "Notes:\n",
        "* `numpy.cumsum(a, axis=None)`\n",
        "    * Return the cumulative sum of the elements along a given axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qjt4yCnUBulx",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "a = np.array([[1,2,3], [4,5,6]])\n",
        "\n",
        "# numpy.cumsum\n",
        "print(f'{a}\\n')\n",
        "print(f'{np.cumsum(a)}\\n')\n",
        "print(f'{np.cumsum(a, axis=0)}\\n') # sum over rows for each of the 3 columns\n",
        "print(f'{np.cumsum(a, axis=1)}\\n') # sum over columns for each of the 2 rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6idDXyTIBulx"
      },
      "source": [
        "Notes:\n",
        "* `numpy.insert(arr, obj, values, axis=None)`\n",
        "    * Insert values along the given axis before the given indices.\n",
        "    * `arr` : *array_like*. Input array.\n",
        "    * `obj` : *int, slice or sequence of ints*. Object that defines the index or indices before which `values` is inserted.\n",
        "    * `axis` : *int, optional*. Axis along which to insert `values`.  If `axis` is None then `arr` is flattened first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wX7WMGqqBulx",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# numpy.insert\n",
        "# Axis parameter not passed. The input array is flattened before insertion.\n",
        "print(f'{np.insert(a,3,[11,12])}\\n')\n",
        "\n",
        "# Axis parameter passed. The values array is broadcast to match input array.\n",
        "#along axis 0\n",
        "print(f'{np.insert(a,1,11,axis = 0)}\\n')\n",
        "\n",
        "#along axis 1\n",
        "print(f'{np.insert(a,1,11,axis = 1)}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6Ulp9oiBulx"
      },
      "source": [
        "8. Run the simulations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VFfRjPTbBulx"
      },
      "outputs": [],
      "source": [
        "# use the function defined earlier\n",
        "gbm_simulations = simulate_gbm(S_0, mu, sigma, N_SIM, T, N)\n",
        "np.shape(gbm_simulations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL2HusXeBulx"
      },
      "source": [
        "9. Plot simulation results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SaYYDICpBulx",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# prepare objects for plotting\n",
        "\n",
        "# get the dates\n",
        "last_train_date = train.index[-1].date() # select the last index in training set\n",
        "first_test_date = test.index[0].date()\n",
        "last_test_date = test.index[-1].date()\n",
        "\n",
        "# add title\n",
        "plot_title = (f'{RISKY_ASSET} Simulation '\n",
        "              f'({first_test_date}:{last_test_date})')\n",
        "\n",
        "# select the indices (DatetimeIndex) of adjusted prices in the testing set\n",
        "selected_indices = adj_close[last_train_date:last_test_date].index\n",
        "\n",
        "# extract the dates from the indices\n",
        "index = [date.date() for date in selected_indices]\n",
        "\n",
        "# use a DataFrame to hold `gbm_simulations` data for plotting\n",
        "gbm_simulations_df = pd.DataFrame(np.transpose(gbm_simulations), index=index)\n",
        "# transpose the marix to match with `index`  set the index\n",
        "\n",
        "# plotting\n",
        "ax = gbm_simulations_df.plot(alpha=0.2, legend=False) # `alpha=0.2`: make the lines transparent to help the two lines stand out\n",
        "\n",
        "# add a line for the average value of all sample pathsb\n",
        "line_1, = ax.plot(index, gbm_simulations_df.mean(axis=1),\n",
        "                  color='red')\n",
        "# add a line for actual stock price of Microsoft in the test set\n",
        "line_2, = ax.plot(index, adj_close[last_train_date:last_test_date],\n",
        "                  color='blue')\n",
        "ax.set_title(plot_title, fontsize=16)\n",
        "ax.legend((line_1, line_2), ('mean', 'actual'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZOgfFB_Buly"
      },
      "source": [
        "Notes:\n",
        "* *list unpacking*\n",
        "    * Unpack values from a list into variables.\n",
        "    * `,` is used for argument unpacking.\n",
        "    * `line_1, = ax.plot(index, gbm_simulations_df.mean(axis=1),color='red')`: `plot` returns a single-element `list`, which is unpacked into `line`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "61SPEhC-Buly"
      },
      "outputs": [],
      "source": [
        "# unpacking\n",
        "a=[1]\n",
        "print(a,type(a))\n",
        "a,=[1]\n",
        "print(a,type(a))\n",
        "\n",
        "\n",
        "# list unpacking\n",
        "name = ['Tom', 'Alice', 'Jerry']\n",
        "Tom = name[0]\n",
        "Alice = name[1]\n",
        "Jerry = name[2]\n",
        "print(Tom, Alice, Jerry)\n",
        "Tom, Alice, Jerry = name\n",
        "print(Tom, Alice, Jerry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gzj3QVXBuly"
      },
      "source": [
        "In the above plot, we observe that the average value from the simulations exhibits a positive trend due to the positive drift term.\n",
        "\n",
        "Bear in mind that this visualization is only feasible for a reasonable number of sample paths. In real-life cases, we want to use significantly more sample paths than 100, as usually the more sample paths, the more accurate/reliable the results are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaBTS822Buly"
      },
      "source": [
        "Summary:\n",
        "\n",
        "1. In Steps 2 to 4, we downloaded Microsoft's stock prices and calculated simple returns. In the next step, we divided the data into the training and test sets. We calculated the average and standard deviation of the returns from the training set to obtain the drift (`mu`) and diffusion (`sigma`) coefficients, which we used later for simulations. Additionally, in Step 6, we defined the following parameters:\n",
        "\n",
        "    * T: Forecasting horizon; in this case, the number of days in the test set.\n",
        "    * N: Number of time increments in the forecasting horizon.\n",
        "    * S_0: Initial price. For this simulation, we take the last observation from the training set.\n",
        "    * N_SIM: Number of simulated paths.\n",
        "\n",
        "    Monte Carlo simulations use a process called **discretization**. The idea is to approximate the continuous pricing of financial assets by splitting the considered time horizon into a large number of discrete intervals. That is why, except for considering the forecasting horizon, we also need to indicate the number of time increments to fit into the horizon.\n",
        "\n",
        "2. Step 7 is where we defined the function for running the simulations. It is good practice to define a function/class for such a problem, as it will also come in handy in the following recipes. We started by defining the time increment (`dt`) and the Brownian increments (`dW`). In the matrix of increments (size: `n_sims x N`), each row describes one sample path. From there, we calculated the Brownian paths (`W`) by running a cumulative sum (`np.cumsum`) over the rows. Then, we created a matrix containing the time steps (`time_steps`). To do so, we created an array of evenly spaced values within an interval (the horizon of the simulation). For that, we used `np.linspace`. Afterward, we broadcasted the array to the intended shape using `np.broadcast_to`. We used the closed-form formula to calculate the stock price at each point in time. Finally, we inserted the initial value into the first position of each row.\n",
        "\n",
        "    There was no explicit need to broadcast the vector containing time steps. It would have been done automatically to match the required dimensions (the dimension of `W`). However, in languages such as R, there is no automatic broadcasting. This also gives us more control over what we are doing and makes the code easier to debug.\n",
        "\n",
        "    In the preceding steps, we can recognize the drift as `(mu - 0.5 * sigma ** 2) * time_steps` and the diffusion as `sigma * W`.\n",
        "\n",
        "    While defining this function, we followed the vectorized approach. By doing so, we avoided writing any `for` loops, which would be inefficient in the case of large simulations.\n",
        "\n",
        "3. In Step 8, we visualized the simulated sample paths. To do so, we transposed the data and converted it into a `pandas` DataFrame. We did the transposition so that we had one path per column, which simplifies using the `plot` method of `pandas` DataFrame. This can also be done using pure `matplotlib`. Aside from the main plot, we added two extra lines. The first one represents the average value of all sample paths at a given point in time. The second one is the actual stock price of Microsoft in the test set. To visualize the simulated stock prices, we chose `alpha=0.2` to make the lines transparent. By doing this, it is easier to see the two extra lines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRlmE2LMBulz"
      },
      "source": [
        "### There's more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq8mjMWVBulz"
      },
      "source": [
        "There are some statistical methods that make working with Monte Carlo simulations easier (higher accuracy, faster computations). One of them is a variance reduction method called **antithetic variates**. In this approach, we try to reduce the variance of the estimator by introducing negative dependence between pairs of random draws. This translates into the following: when creating sample paths, for each $[\\epsilon_1,...,\\epsilon_t]$, we also take the antithetic values $[-\\epsilon_1,...,-\\epsilon_t]$.\n",
        "\n",
        "$Var(\\frac{X+Y}{2})=\\frac{1}{4}(Var(X)+Var(Y)+2Cov(X,Y))$\n",
        "\n",
        "The advantages of this approach are:\n",
        "* Reduction (by half) of the number of Standard Normal samples to be drawn in order to generate N paths\n",
        "* Reduction of the sample path variance, while at the same time, improving the accuracy\n",
        "\n",
        "We implemented this approach in the `simulate_gbm` function. Additionally, we made the function shorter by putting the majority of the calculations into one line.\n",
        "\n",
        "Before we implemented these changes, we timed the old version of the function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0Y0ul3XwBulz",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "%timeit gbm_simulations = simulate_gbm(S_0, mu, sigma, N_SIM, T, N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1HgYEo6Bulz"
      },
      "source": [
        "Notes:\n",
        "* `%timeit` is an ipython magic function, which can be used to time a particular piece of code (A single execution statement, or a single method).\n",
        "\n",
        "* If you wanted to see all of the magics you can use, you could simply type: `%lsmagic` to get a list of both line magics and cell magics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "394tLX7xBulz"
      },
      "source": [
        "The new function is defined as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qsSnXbyyBulz"
      },
      "outputs": [],
      "source": [
        "def simulate_gbm(s_0, mu, sigma, n_sims, T, N, random_seed=42, antithetic_var=False):\n",
        "    '''\n",
        "    Function used for simulating stock returns using Geometric Brownian Motion.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    s_0 : float\n",
        "        Initial stock price\n",
        "    mu : float\n",
        "        Drift coefficient\n",
        "    sigma : float\n",
        "        Diffusion coefficient\n",
        "    n_sims : int\n",
        "        Number of simulations paths\n",
        "    dt : float\n",
        "        Time increment, most commonly a day\n",
        "    T : float\n",
        "        Length of the forecast horizon, same unit as dt\n",
        "    N : int\n",
        "        Number of time increments in the forecast horizon\n",
        "    random_seed : int\n",
        "        Random seed for reproducibility\n",
        "    antithetic_var : bool\n",
        "        Boolean whether to use antithetic variates approach to reduce variance\n",
        "\n",
        "    Returns\n",
        "    -----------\n",
        "    S_t : np.ndarray\n",
        "        Matrix (size: n_sims x (T+1)) containing the simulation results.\n",
        "        Rows respresent sample paths, while columns point of time.\n",
        "    '''\n",
        "\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    # time increment\n",
        "    dt = T/N\n",
        "\n",
        "    # Brownian\n",
        "    if antithetic_var:\n",
        "        dW_ant = np.random.normal(scale = np.sqrt(dt),\n",
        "                                  size=(int(n_sims/2), N + 1)) # we generate a more column as we will directly replace the first column with the initial value\n",
        "        dW = np.concatenate((dW_ant, -dW_ant), axis=0) # join along column\n",
        "    else:\n",
        "        dW = np.random.normal(scale = np.sqrt(dt),\n",
        "                              size=(n_sims, N + 1))\n",
        "\n",
        "    # simulate the evolution of the process\n",
        "    S_t = s_0 * np.exp(np.cumsum((mu - 0.5 * sigma ** 2) * dt + sigma * dW,\n",
        "                                 axis=1))\n",
        "    # add the initial price\n",
        "    S_t[:, 0] = s_0\n",
        "\n",
        "    return S_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARrP_yHgBulz"
      },
      "source": [
        "Notes:\n",
        "* `numpy.concatenate((a1, a2, ...), axis=0)`\n",
        "    * Join a sequence of arrays along an existing axis.\n",
        "    * `a1, a2, …`: *sequence of array_like*. The arrays must have the same shape, except in the dimension corresponding to axis (the first, by default).\n",
        "    * `axis`: *int, optional*. The axis along which the arrays will be joined. If axis is None, arrays are flattened before use. Default is 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YFeavAVVBulz"
      },
      "outputs": [],
      "source": [
        "# np.concatenate\n",
        "a = np.array([[1, 2], [3, 4]])\n",
        "b = np.array([[5, 6]])\n",
        "print(f'{a}\\n')\n",
        "print(f'{b}\\n')\n",
        "print(f'{np.concatenate((a, b))}\\n') # default: axis=0\n",
        "print(f'{np.concatenate((a, b.transpose()),axis=1)}\\n')\n",
        "print(f'{np.concatenate((a, b.transpose()),axis=None)}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6fEjPJrSBulz"
      },
      "outputs": [],
      "source": [
        "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(a)\n",
        "np.sum(a, axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M7_ZkFYBul0"
      },
      "source": [
        "First, we run the simulations without antithetic variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gbOToHDEBul0"
      },
      "outputs": [],
      "source": [
        "%timeit gbm_simulations = simulate_gbm(S_0, mu, sigma, N_SIM, T, N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFwoOUX5Bul0"
      },
      "source": [
        "Then, we run the simulations with them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CMSUe-M4Bul0"
      },
      "outputs": [],
      "source": [
        "%timeit gbm_simulations = simulate_gbm(S_0, mu, sigma, N_SIM, T, N, antithetic_var=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXTjzGoLBul0"
      },
      "source": [
        "We succeeded in making the function faster. If you are interested in pure performance, these simulations can be further expedited using `Numba`, `Cython`, or `multiprocessing`.\n",
        "\n",
        "Other possible variance reduction techniques include:\n",
        "\n",
        "* Control variates\n",
        "* Common random numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGa5PAVjBul0"
      },
      "source": [
        "## Pricing European Options using Simulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW3tOY6YBul0"
      },
      "source": [
        "Options are a type of derivative instrument because their price is linked to the price of the underlying security, such as stock. Buying an options contract grants the right, but not the obligation, to buy or sell an underlying asset at a set price (known as a strike) on/before a certain date. The main reason for the popularity of options is because they hedge away exposure to an asset's price moving in an undesirable way.\n",
        "\n",
        "A European call/put option gives us the right (but again, no obligation) to buy/sell a certain asset on a certain expiry date (commonly denoted as *T*).\n",
        "\n",
        "Some popular methods of options' valuation:\n",
        "\n",
        "* Using analytic formulas\n",
        "* Binomial tree approach\n",
        "* Finite differences\n",
        "* Monte Carlo simulations\n",
        "\n",
        "European options are an exception in the sense that there exist an analytical formula for their valuation, which is not the case for more advanced derivatives, such as American or Exotic options.\n",
        "\n",
        "To price options using Monte Carlo simulations, we use risk-neutral valuation, under which the fair value of a derivative is the expected value of its future payoff(s). In other words, we assume that the option premium grows at the same rate as the risk-free rate, which we use for discounting to the present value. For each of the simulated paths, we calculate the option's payoff at maturity, take the average of all the paths, and discount it to the present value.\n",
        "\n",
        "In this recipe, we show how to code the closed-form solution to the Black-Scholes model and then use the simulation approach. For simplicity, we use fictitious input data, but real-life data could be used analogically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTPt6hyFBul0"
      },
      "source": [
        "### How to do it..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzmWM8DaBul0"
      },
      "source": [
        "1. Import the libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SBVDjqDlBul1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from chapter_6_utils import simulate_gbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks-VRFYwBul1"
      },
      "source": [
        "Remarks:\n",
        "* Download `chapter_6_utils.py` here and put the file in your working directory.\n",
        "https://github.com/PacktPublishing/Python-for-Finance-Cookbook/blob/master/Chapter%2006/chapter_6_utils.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD3dEtbCBul1"
      },
      "source": [
        "2. Define the parameters for the valuation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d3fWQ2nvBul1"
      },
      "outputs": [],
      "source": [
        "S_0 = 100\n",
        "K = 100\n",
        "r = 0.05\n",
        "sigma = 0.50\n",
        "T = 1 # 1 year\n",
        "N = 252 # 252 days in a year\n",
        "dt = T / N # time step\n",
        "N_SIMS = 1000000 # number of simulations\n",
        "discount_factor = np.exp(-r * T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xObQ0eg_Bul1"
      },
      "source": [
        "3. Define the function using the analytical solution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ekylOtKWBul1"
      },
      "outputs": [],
      "source": [
        "def black_scholes_analytical(S_0, K, T, r, sigma, type='call'):\n",
        "    '''\n",
        "    Function used for calculating the price of European options using the analytical form of the Black-Scholes model.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    s_0 : float\n",
        "        Initial stock price\n",
        "    K : float\n",
        "        Strike price\n",
        "    T : float\n",
        "        Time to maturity in years\n",
        "    r : float\n",
        "        Annualized risk-free rate\n",
        "    sigma : float\n",
        "        Standard deviation of the stock returns\n",
        "    type : str\n",
        "        Type of the option. Allowable: ['call', 'put']\n",
        "\n",
        "    Returns\n",
        "    -----------\n",
        "    option_premium : float\n",
        "        The premium on the option calculated using the Black-Scholes model\n",
        "    '''\n",
        "\n",
        "    d1 = (np.log(S_0 / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
        "    d2 = (np.log(S_0 / K) + (r - 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
        "\n",
        "    if type == 'call':\n",
        "         # the formula for the price of a European call option\n",
        "        val = (S_0 * norm.cdf(d1, 0, 1) - K * np.exp(-r * T) * norm.cdf(d2, 0, 1))\n",
        "    elif type == 'put':\n",
        "         # the formula for the price of a European put option\n",
        "        val = (K * np.exp(-r * T) * norm.cdf(-d2, 0, 1) - S_0 * norm.cdf(-d1, 0, 1))\n",
        "    else:\n",
        "        raise ValueError('Wrong input for type!')\n",
        "\n",
        "    return val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utcysuycBul1"
      },
      "source": [
        "Notes:\n",
        "* Raising an Exception\n",
        "    * We can use raise to throw an exception if a condition occurs. The statement can be complemented with a custom exception."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VZkxGkmlBul2"
      },
      "outputs": [],
      "source": [
        "# raise a custom exception\n",
        "# x = 10\n",
        "# if x > 5:\n",
        "#     raise Exception('x should not exceed 5. The value of x was: {}'.format(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffcGkn_pBul2"
      },
      "source": [
        "4. Valuate the call option using the specified parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fTshUbUXBul2"
      },
      "outputs": [],
      "source": [
        "# calculate the benchmark for the Monte Carlo simulations\n",
        "black_scholes_analytical(S_0=S_0, K=K, T=T, r=r, sigma=sigma, type='call')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPSxwMfhBul2"
      },
      "source": [
        "5. Simulate the stock path using GBM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7YmGnnImBul2"
      },
      "outputs": [],
      "source": [
        "gbm_sims = simulate_gbm(s_0=S_0, mu=r, sigma=sigma,\n",
        "                       n_sims=N_SIMS, T=T, N=N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJolx_ohBul4"
      },
      "source": [
        "6. Calculate the option premium:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HOQhbGgwBul4"
      },
      "outputs": [],
      "source": [
        "# use the terminal value and take the average of the payoffs and discount it to present the value by using the discount factor\n",
        "premium = discount_factor * np.mean(np.maximum(0, gbm_sims[:, -1] - K))\n",
        "premium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViIKcPU4Bul4"
      },
      "source": [
        "The calculated option premium is 21.7562.\n",
        "\n",
        "Here, we can see that the option premium that we calculated using Monte Carlo simulations is close to the one from a closed-form solution of the Black-Scholes model. To increase the accuracy of the simulation, we could increase the number of simulated paths (using the `n_sims` parameter)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbbdsUmNBul5"
      },
      "source": [
        "Summary:\n",
        "\n",
        "1. In Step 2, we defined the parameters that we used for this recipe:\n",
        "\n",
        "    * S_0: Initial stock price\n",
        "    * K: Strike price, that is, the one we can buy/sell for at maturity\n",
        "    * r: Annual risk-free rate\n",
        "    * sigma: Underlying stock volatility (annualized)\n",
        "    * T: Time until maturity in years\n",
        "    * N: Number of time increments for simulations\n",
        "    * n_sims: Number of simulated sample paths\n",
        "    * discount_factor: Discount factor, which is used to calculate the present value of the future payoff\n",
        "\n",
        "2. In Step 3, we defined a function for calculating the option premium using the closed-form solution to the Black-Scholes model (for non-dividend-paying stocks). We used it in Step 4 to calculate the benchmark for the Monte Carlo simulations.\n",
        "\n",
        "    The analytical solution to the call and put options is:<br>\n",
        "<center>$C(S_t,t)=N(d_1)S_t-N(d_2)Ke^{-r(T-t)}$ <br>$P(S_t,t)=N(-d_2)Ke^{-r(T-t)}-N(-d_1)S_t$ <br>\n",
        "$d_1=\\frac{1}{\\sigma\\sqrt{T-t}} [ln(\\frac{S_t}{K})+(r+\\frac{\\sigma^2}{2}){(T-t)}]$ <br>\n",
        "$d_2=d_1-\\sigma\\sqrt{T-t}$</center>\n",
        "\n",
        "    Here, $N()$ stands for the **cumulative distribution function (CDF)** of the Standard Normal distribution and $T - t$ is the time to maturity expressed in years. Equation 1 represents the formula for the price of a European call option, while equation 2 represents the price of the European put option. Informally, the two terms in equation 1 can be thought of as:\n",
        "\n",
        "    * The current price of the stock, weighted by the probability of exercising the option to buy the stock ($N(d_1)$) – in other words, what we could receive.\n",
        "    * The discounted price of exercising the option (strike), weighted by the probability of exercising the option ($N(d_2)$) – in other words, what we are going to pay.\n",
        "\n",
        "3. In Step 5, we used the GBM simulation function from the previous recipe to obtain 1,000,000 possible paths of the underlying asset. To calculate the option premium, we only looked at the terminal values, and for each path, calculated the payoff as follows:\n",
        "\n",
        "    * $max(S_T-K,0)$ for the call option\n",
        "    * $max(K-S_T,0)$ for the put option\n",
        "\n",
        "4. In Step 6, we took the average of the payoffs and discounted it to present the value by using the discount factor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA2xdgnvBul5"
      },
      "source": [
        "### There's more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO1KSwo2Bul5"
      },
      "source": [
        "In the previous steps, we showed you how to reuse the GBM simulation to calculate the\n",
        "European call option premium. However, we can make the calculations faster, as in the case\n",
        "of European options we are only interested in the terminal stock price. The intermediate\n",
        "steps do not matter. That is why we only need to simulate the price at time $T$ and use these\n",
        "values to calculate the expected payoff. We show how to do this by using an example of a\n",
        "European put option with the same parameters as we used before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UOYj0_guBul5",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# calculating the option premium using the analytical formula\n",
        "black_scholes_analytical(S_0=S_0, K=K, T=T, r=r, sigma=sigma, type='put')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MR5XwygaBul5"
      },
      "outputs": [],
      "source": [
        "# define the modified simulation function\n",
        "def european_option_simulation(S_0, K, T, r, sigma, n_sims, type='call', random_seed=42):\n",
        "    '''\n",
        "    Function used for calculating the price of European options using Monte Carlo simulations.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    S_0 : float\n",
        "        Initial stock price\n",
        "    K : float\n",
        "        Strike price\n",
        "    T : float\n",
        "        Time to maturity in years\n",
        "    r : float\n",
        "        Annualized risk-free rate\n",
        "    sigma : float\n",
        "        Standard deviation of the stock returns\n",
        "    n_sims : int\n",
        "        Number of paths to simulate\n",
        "    type : str\n",
        "        Type of the option. Allowable: ['call', 'put']\n",
        "    random_seed : int\n",
        "        Random seed for reproducibility\n",
        "\n",
        "    Returns\n",
        "    -----------\n",
        "    option_premium : float\n",
        "        The premium on the option calculated using Monte Carlo simulations\n",
        "    '''\n",
        "    # set seed\n",
        "    np.random.seed(random_seed)\n",
        "    rv = np.random.normal(0, 1, size=n_sims)\n",
        "    # simulate the price at time 𝑇 using the closed-form formula\n",
        "    S_T = S_0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * rv)\n",
        "\n",
        "    # calculate the payoff\n",
        "    if type == 'call':\n",
        "        payoff = np.maximum(0, S_T - K)\n",
        "    elif type == 'put':\n",
        "        payoff = np.maximum(0, K - S_T)\n",
        "    else:\n",
        "        raise ValueError('Wrong input for type!')\n",
        "\n",
        "    # take the average of the payoffs and discount it to present the value\n",
        "    premium = np.mean(payoff) * np.exp(-r * T)\n",
        "    return premium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EGpOQE8wBul5"
      },
      "outputs": [],
      "source": [
        "european_option_simulation(S_0, K, T, r, sigma, N_SIMS, type='put')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uABpB9NBul5"
      },
      "source": [
        "The two values are close to each other. Further increasing the\n",
        "number of simulated paths should increase the accuracy of the valuation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zR78UjG0Cv3"
      },
      "source": [
        "https://diposit.ub.edu/dspace/bitstream/2445/110072/2/memoria.pdf\n",
        "\n",
        "https://s2pnd-matematika.fkip.unpatti.ac.id/wp-content/uploads/2019/03/Marek-Capinski-Peter-E.-Kopp-Measure-integral-and-probability-Springer-2004.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNjEEengBul5"
      },
      "source": [
        "## Pricing American Options with Least Squares Monte Carlo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOptXvFnBul5"
      },
      "source": [
        "In this recipe, we learn how to valuate American options. The key difference between European and American options is that the latter can be exercised at any time before and including the maturity date – basically, whenever the underlying asset's price moves favorably for the option holder.\n",
        "\n",
        "This behavior introduces additional complexity to the valuation and there is no closed-form solution to this problem. When using Monte-Carlo simulations, we cannot only look at the terminal value on each sample path, as the option's exercise can happen anywhere along the path. That is why we need to employ a more sophisticated approach called **Least Squares Monte Carlo (LSMC)**, which was introduced by Longstaff and Schwartz (2001).\n",
        "\n",
        "First of all, the time axis spanning $[0,T]$ is discretized into a finite number of equally spaced intervals and the early exercise can happen only at those particular time-steps. Effectively, the American option is approximated by a Bermudan one. For any time step $t$, the early exercise is performed in case the payoff from immediate exercise is larger than the continuation value.\n",
        "\n",
        "This is expressed by the following formula:<br>\n",
        "<center>$V_t(s)=max(h_t(s),C_t(s))$</center>\n",
        "Here, $h_t(s)$ stands for the option's payoff (also called the option's inner value, calculated as in the case of European options) and $C_t(s)$ is the continuation value of the option, which is defined as :<br>\n",
        "<center>$C_t(s)=E^Q_t[e^{-rdt}V_{t+dt}(S_{t+dt})|S_t=s]$</center>\n",
        "\n",
        "Here, $r$ is the risk-free rate, $dt$ is the time increment, and $E^Q_t(...|S_t=s)$ is the risk-neutral expectation given the underlying price. The continuation value is basically the expected payoff from not exercising the option at a given time.\n",
        "\n",
        "When using Monte Carlo simulations, we can define the continuation value for each path and time as $e^{-rdt}V_{t}+d_{t,i}$, where $i$ indicates the sample path. Using this value directly is not possible as this would imply perfect foresight. That is why the LSMC algorithm uses linear regression to estimate the expected continuation value. In the algorithm, we regress the discounted future values (obtained from keeping the option) onto a set of basis functions of the spot price (time $t$ price). The simplest way to approach this is to use an $x$-degree polynomial regression. Other options for the basis functions include Legendre, Hermite, Chebyshev, Gegenbauer, or Jacobi polynomials.\n",
        "\n",
        "We iterate this algorithm backward (from time $T-1$ to $0$) and at the last step take the average discounted value as the option premium. The premium of a European option represents the lower bound to the American option's premium. The difference is usually called the early exercise premium."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u13UK8BBBul6"
      },
      "source": [
        "### How to do it..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_AFnGEGBul6"
      },
      "source": [
        "1. Import the libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tSquBx53Bul6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from chapter_6_utils import (simulate_gbm,\n",
        "                             black_scholes_analytical,\n",
        "                             lsmc_american_option)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vatz50oqBul6"
      },
      "source": [
        "2. Define the parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TMg3fotBBul6"
      },
      "outputs": [],
      "source": [
        "S_0 = 36 # Initial stock price\n",
        "K = 40 # Strike price, that is, the one we can buy/sell for at maturity\n",
        "r = 0.06 # Annual risk-free rate\n",
        "sigma = 0.2 # Underlying stock volatility (annualized)\n",
        "T = 1 # Time until maturity in years\n",
        "N = 50 # Number of time increments for simulations\n",
        "dt = T / N\n",
        "N_SIMS = 10 ** 5 # Number of simulated sample paths\n",
        "discount_factor = np.exp(-r * dt) #Discount factor, which is used to calculate the present value of the future payoff\n",
        "OPTION_TYPE = 'put'\n",
        "POLY_DEGREE = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYOffBzfBul6"
      },
      "source": [
        "3. Simulate the stock prices using GBM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EA69dvDTBul6"
      },
      "outputs": [],
      "source": [
        "gbm_sims = simulate_gbm(s_0=S_0, mu=r, sigma=sigma, n_sims=N_SIMS,\n",
        "                        T=T, N=N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2DzeM9PBul6"
      },
      "source": [
        "4. Calculate the payoff matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LKua1OLjBul6"
      },
      "outputs": [],
      "source": [
        "payoff_matrix = np.maximum(K - gbm_sims, np.zeros_like(gbm_sims)) # compare K - S_T with 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjIMWEvFBul6"
      },
      "source": [
        "Notes:\n",
        "* `numpy.zeros_like(a)`\n",
        "    * Return an array of zeros with the same shape and type as a given array.\n",
        "    * `a` : *array_like*. The shape and data-type of `a` define these same attributes of the returned array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e8zlky6ZBul7"
      },
      "outputs": [],
      "source": [
        "example=([1,2],[3,4])\n",
        "np.zeros_like(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO6Bg3PSBul7"
      },
      "source": [
        "5. Define the value matrix and fill in the last column (time T):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PDIbzDRZBul7"
      },
      "outputs": [],
      "source": [
        "# matrix of option values over time\n",
        "value_matrix = np.zeros_like(payoff_matrix)  # define a matrix of zeros of the same size as the payoff matrix\n",
        "value_matrix[:, -1] = payoff_matrix[:, -1] # fill the last column of the value matrix with the last column of the payoff matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ky3vJIbDKvYy"
      },
      "outputs": [],
      "source": [
        "value_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zmBkz9-xEvIM"
      },
      "outputs": [],
      "source": [
        "value_matrix[:,-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOjRAM5TBul7"
      },
      "source": [
        "6. Iteratively calculate the continuation value and the value vector in the given time:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV1ArSWuBul7"
      },
      "source": [
        "![flowchart](https://raw.githubusercontent.com/songssssss/notebook-repo/0b67215646f8916048ca2cfab0827bff81975b04/chp6%20flowchart.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "vlccstarBul7"
      },
      "outputs": [],
      "source": [
        "# iterate the algorithm backward (from time T−1 to 0)\n",
        "for t in range(N - 1, 0 , -1):\n",
        "    # regress the discounted future values (obtained from keeping the option) onto a set of basis functions of the spot price (time t price)\n",
        "    regression = np.polyfit(gbm_sims[:, t],\n",
        "                            value_matrix[:, t + 1] * discount_factor,\n",
        "                            POLY_DEGREE)\n",
        "    # estimate the expected continuation value (getting the fitted values from the regression)\n",
        "    continuation_value = np.polyval(regression, gbm_sims[:, t])\n",
        "    # compare the expected continuation value to the payoff to see if the option should be exercised\n",
        "    value_matrix[:, t] = np.where(\n",
        "        payoff_matrix[:, t] > continuation_value, # If the payoff was higher than the expected value from continuation\n",
        "        payoff_matrix[:, t], #  we set the value to the payoff\n",
        "        value_matrix[:, t + 1] * discount_factor  # Otherwise, we set it to the discounted one-step-ahead value\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rassi2AXBul7"
      },
      "source": [
        "Notes:\n",
        "* `numpy.polyfit(x, y, deg)`\n",
        "    * Least squares polynomial fit.\n",
        "    * `x` : array_like, shape (M,). x-coordinates of the M sample points.\n",
        "    * `y` : array_like, shape (M,). y-coordinates of the sample points.\n",
        "    * `deg` : *int*. Degree of the fitting polynomial.\n",
        "    * Returns a vector of coefficients `p` that minimises the squared error in the order `deg`, `deg-1`, ... `0`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPZZeCAbBul7"
      },
      "source": [
        "Remarks:\n",
        "* It is also possible to use `scikit-learn` for the polynomial fit. To do so, you need to combine `LinearRegression` with `PolynomialFeatures`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D3WsMdLzBul7",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# np.polyfit\n",
        "egt = 1 # choose time t=1 as an example\n",
        "X = gbm_sims[:, egt]\n",
        "Y = value_matrix[:, egt + 1] * discount_factor\n",
        "\n",
        "example1 = np.polyfit(X,\n",
        "                      Y,\n",
        "                      POLY_DEGREE)\n",
        "example1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eyClbWV8VYla"
      },
      "outputs": [],
      "source": [
        "value_matrix[:, egt + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7lnhEm48VS4L"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HgbIRlZpVFG6"
      },
      "outputs": [],
      "source": [
        "pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ko7jmY2KBul7"
      },
      "outputs": [],
      "source": [
        "# sklearn.linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "X_ = X.reshape(-1, 1)\n",
        "polynomial_features = PolynomialFeatures(degree = POLY_DEGREE)\n",
        "X_TRANS = polynomial_features.fit_transform(X_)\n",
        "\n",
        "example2 = LinearRegression()\n",
        "example2.fit(X_TRANS, Y).coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diVHGc96Bul8"
      },
      "source": [
        "Notes:\n",
        "* `numpy.array.reshape(shape)`\n",
        "    * Returns an array containing the same data with a new shape.\n",
        "    * The new shape should be compatible with the original shape. If an integer, then the result will be a 1-D array of that length. One shape dimension can be -1. In this case, the value is inferred from the length of the array and remaining dimensions.\n",
        "    * See https://www.codingem.com/numpy-reshape-minus-one/#:~:text=By%20Artturi%20Jalli,elements%20to%20a%201D%20array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Be6FSTQhBul8"
      },
      "outputs": [],
      "source": [
        "a = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "print(a.reshape(2, -1))\n",
        "print(a.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drqMzVgEBul8"
      },
      "source": [
        "Notes:\n",
        "* `numpy.polyval(p, x)`\n",
        "    * Evaluate a polynomial at specific values.\n",
        "    * If `p` is of length N, this function returns the value: ``p[0]*x**(N-1) + p[1]*x**(N-2) + ... + p[N-2]*x + p[N-1]``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "whE7N-YeBul8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# np.polyval\n",
        "np.polyval([3,2,1], 10) # 3*10**2+2*10**1+1*10**0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2GlZRMeBul8"
      },
      "source": [
        "Notes:\n",
        "* `numpy.where(condition[,x,y])`\n",
        "    * `condition` : When True, yield `x`, otherwise yield `y`.\n",
        "    * `x, y` : Values from which to choose.\n",
        "    * Returns:\n",
        "        * If both `x` and `y` are specified, the output array contains elements of `x` where condition is True, and elements from `y` elsewhere.\n",
        "        * If only `condition` is given, return the tuple `condition.nonzero()`, the indices where condition is True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "slJeX5IxBul8"
      },
      "outputs": [],
      "source": [
        "# np.where\n",
        "example = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(example)\n",
        "\n",
        "con=np.where(example<3) # only condition is given, return the indices where the condition is true\n",
        "print(con)\n",
        "\n",
        "print(example[con]) # select the elements that satisfy the condition\n",
        "print(np.where(example<3,'<3','>=3')) # When True, yield '<3', otherwise yield '>=3'\n",
        "\n",
        "# see also (in Chinese): https://blog.csdn.net/caihuanqia/article/details/105428512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKCIa_rBBul8"
      },
      "source": [
        "7. Calculate the option premium:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1O0QqJjWBul8"
      },
      "outputs": [],
      "source": [
        "# take the average discounted t=1 value as the option premium\n",
        "option_premium = np.mean(value_matrix[:, 1] * discount_factor)\n",
        "print(f'The premium on the specified American {OPTION_TYPE} option is {option_premium:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7uNLCYLBul9"
      },
      "source": [
        "8. Calculate the premium of a European put with the same parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4FwoHAQvBul9"
      },
      "outputs": [],
      "source": [
        "euput = black_scholes_analytical(S_0=S_0, K=K, T=T, r=r, sigma=sigma,\n",
        "                         type='put')\n",
        "print(f'The price of European put option with the same parameters is {OPTION_TYPE} option is {euput:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7BWt2ZuBul9"
      },
      "source": [
        "9. As an extra check, calculate the prices of the American and European call options:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iAnt0z6XBul9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "european_call_price = black_scholes_analytical(S_0=S_0, K=K, T=T,\n",
        "                                               r=r, sigma=sigma)\n",
        "american_call_price = lsmc_american_option(S_0=S_0, K=K, T=T, N=N, r=r,\n",
        "                                           sigma=sigma, n_sims=N_SIMS,\n",
        "                                           option_type='call',\n",
        "                                           poly_degree=POLY_DEGREE)\n",
        "# the prices of the American and European call options are close\n",
        "print(f\"The price of the European call is {european_call_price:.3f}, and the American call's price (using {N_SIMS} simulations) is {american_call_price:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl3SaLBeBul9"
      },
      "source": [
        "Remarks:\n",
        "* To make it easier, we put the entire algorithm for LSMC into one function `lsmc_american_option`, which is available in this book's GitHub repository `chapter_6_utils.py`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwMMnrtgBul9"
      },
      "source": [
        "Summary:\n",
        "\n",
        "1. In Step 2, we once again defined the parameters of the considered American option. For comparison's sake, we took the same values that Longstaff and Schwartz (2001) did. In Step 3, we simulated the stock's evolution using the `simulate_gbm` function from the previous recipe. Afterward, we calculated the payoff matrix of the put option using the same formula that we used for the European options.\n",
        "\n",
        "2. In Step 5, we prepared the matrix of option values over time, which we defined as a matrix of zeros of the same size as the payoff matrix. We filled the last column of the value matrix with the last column of the payoff matrix, as at the last step there are no further computations to carry out – the payoff is equal to the European option.\n",
        "\n",
        "3. Step 6 is where we ran the backward part of the algorithm from time $T-1$ to $0$. At each of these steps, we estimated the expected continuation value as a cross-sectional linear regression. We fitted the $5^{th}$-degree polynomial to the data using `np.polyfit`. Then, we evaluated the polynomial at specific values (using `np.polyval`), which is the same as getting the fitted values from a linear regression. We compared the expected continuation value to the payoff to see if the option should be exercised. If the payoff was higher than the expected value from continuation, we set the value to the payoff. Otherwise, we set it to the discounted one-step-ahead value. We used `np.where` for this selection.\n",
        "\n",
        "4. In Step 7 of the algorithm, we obtained the option premium by taking the average value of the discounted $t = 1$ value vector.\n",
        "\n",
        "5. In the last two steps, we carried out some sanity checks regarding the implementation by calculating the option premiums of the European put and call options with the same parameters. For the call option, the premium on the American and European options should be equal, as it is never optimal to exercise the option when there are no dividends. Our results are very close, but we can obtain a more accurate price using more sample paths.\n",
        "\n",
        "    In principle, the Longstaff-Schwartz algorithm should underprice American options because the approximation of the continuation value by the basis functions is just that, an approximation. As a consequence, the algorithm will not always make the correct decision about exercising the option. This, in turn, means that the option's value will be lower than in the case of the optimal exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJClRpEkBul9"
      },
      "source": [
        "## Pricing American Options using Quantlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CgH1omjBul9"
      },
      "source": [
        "In the previous recipe, we showed how to manually code the Longstaff-Schwartz algorithm. However, we can also use already existing frameworks for valuation of derivatives. One of the most popular ones is QuantLib. It is an open source C++ library that provides tools for the valuation of financial instruments. By using **Simplified Wrapper and Interface Generator (SWIG)**, it is possible to use QuantLib from Python (and some other programming languages, such as R or Julia). In this recipe, we show how to price the same American put option that we priced in the *Pricing American options with Least squares Monte Carlo* recipe, but the library itself has many more interesting features to explore."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkT0eRMbBul9"
      },
      "source": [
        "### How to do it..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIRQdJWMBul9"
      },
      "source": [
        "0: Defining parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wLJsM8DWBul-"
      },
      "outputs": [],
      "source": [
        "S_0 = 36 # Initial stock price\n",
        "r = 0.06 # Annual risk-free rate\n",
        "sigma = 0.2 # Underlying stock volatility (annualized)\n",
        "K = 40 # Strike price, that is, the one we can buy/sell for at maturity\n",
        "OPTION_TYPE = 'put'\n",
        "POLY_DEGREE = 5\n",
        "R_SEED = 42 # set seed\n",
        "N_SIMS = 10 ** 5  # Number of simulated sample paths\n",
        "N = 50 # Number of time increments for simulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up5Lb7D9Bul-"
      },
      "source": [
        "1. Import the library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-jZaumJKBul-"
      },
      "outputs": [],
      "source": [
        "pip install QuantLib;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yCwqAMSIBul-"
      },
      "outputs": [],
      "source": [
        "import QuantLib as ql"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeCvoXxzBul-"
      },
      "source": [
        "Notes:\n",
        "\n",
        "* `QuantLib`\n",
        "    * The QuantLib project is aimed at providing a comprehensive software framework for quantitative finance. QuantLib is a free/open-source library for modeling, trading, and risk management in real-life. QuantLib offers tools that are useful both for practical implementation and for advanced modeling, with features such as market conventions, yield curve models, solvers, PDEs, Monte Carlo (low-discrepancy included), exotic options, VAR, and so on. For the documentation of QuantLib, please visit https://www.quantlib.org/reference/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID7l1Zv1Bul-"
      },
      "source": [
        "#### Quantlib Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wge3g_icBul-"
      },
      "source": [
        "##### Date Class\n",
        "\n",
        "The `Date` object can be created using the constructor as `Date(day, month, year)`. It would be worthwhile to pay attention to the fact that `day` is the first argument, followed by `month` and then the `year`. This is different from the `python datetime` object instantiation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-yAUOT56Bul-",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "date = ql.Date(23, 7, 2021)\n",
        "#date = ql.Date(1, 4, 2022)\n",
        "print(date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3_pNIStBul-"
      },
      "source": [
        "##### Calendar Class\n",
        "\n",
        "The `Date` arithmetic above did not take holidays into account. But valuation of different securities would require taking into account the holidays observed in a specific exchange or country. The `Calendar` class implements this functionality for all the major exchanges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wLWm122hBul-"
      },
      "outputs": [],
      "source": [
        "hk_calendar = ql.HongKong()\n",
        "period = ql.Period(2, ql.Days)\n",
        "\n",
        "print(\"Add 2 days in HK:\", date + period)\n",
        "print(\"Add 2 business days in HK:\", hk_calendar.advance(date, period))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLJrK-9lBul_"
      },
      "source": [
        "##### Interest Rate\n",
        "\n",
        "The `InterestRate` class can be used to store the interest rate with the compounding type, day count and the frequency of compounding. Below we show how to create an interest rate of 6.0% compounded annually, using Actual/Actual day count convention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uiRaklDCBul_"
      },
      "outputs": [],
      "source": [
        "annual_rate = 0.06\n",
        "day_count = ql.ActualActual(0)\n",
        "  #`ActualActual()` Actual/Actual day count\n",
        "compound_type = ql.Compounded\n",
        "frequency = ql.Annual\n",
        "interest_rate = ql.InterestRate(annual_rate, day_count, compound_type, frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kBVmvYw8Bul_",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "t = 2.0\n",
        "print(interest_rate.compoundFactor(t))\n",
        "print((1+annual_rate)*(1.0+annual_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phX-o8fPBul_"
      },
      "source": [
        "##### Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rJo1wKZlBul_",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# today's date is returned if the evaluation date is set to the null date (its default value)\n",
        "d = ql.Settings.instance().evaluationDate\n",
        "print('Eval Date :', d)\n",
        "\n",
        "# we can set it to a new value\n",
        "ql.Settings.instance().evaluationDate = ql.Date(1, ql.January, 2020)\n",
        "d = ql.Settings.instance().evaluationDate\n",
        "print('New Eval Date :', d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNoAEGKsBul_"
      },
      "source": [
        "##### Instruments and pricing engines\n",
        "\n",
        "Take a European option as a sample instrument. Building the option requires only the specification of its contract, so its payoff (it’s a call option with strike at 100) and its exercise, three months from today’s date. Market data will be selected and passed later, depending on the calculation methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dWdjhVhGBul_"
      },
      "outputs": [],
      "source": [
        "option = ql.EuropeanOption(ql.PlainVanillaPayoff(ql.Option.Call, 100.0),\n",
        "                        ql.EuropeanExercise(ql.Date(3, ql.September, 2021)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpUAW634Bul_"
      },
      "source": [
        "Take the analytic Black-Scholes formula as a sample pricing engine\n",
        "\n",
        "First, we collect the quoted market data. We’ll assume flat risk-free rate and volatility, so they can be expressed by `SimpleQuote` instances. The underlying value is at 100, the risk-free value at 1%, and the volatility at 20%.\n",
        "\n",
        "* `Quote` instances: those model numbers whose value can change and that can notify observers when this happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "huTKJfGoBul_"
      },
      "outputs": [],
      "source": [
        "u = ql.SimpleQuote(100.0)\n",
        "r = ql.SimpleQuote(0.01)\n",
        "sigma = ql.SimpleQuote(0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tX3nZUUBul_"
      },
      "source": [
        "In order to build the engine, the market data are encapsulated in a Black-Scholes process object.\n",
        "\n",
        "Before that, we need to build flat curves for the risk-free rate and the volatility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BT8Y9NDUBumA"
      },
      "outputs": [],
      "source": [
        "riskFreeCurve = ql.FlatForward(0, hk_calendar, ql.QuoteHandle(r), day_count)\n",
        "volatility = ql.BlackConstantVol(0, hk_calendar, ql.QuoteHandle(sigma), day_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ige3f_j7BumA"
      },
      "source": [
        "We instantiate the process with the underlying value and the curves we just built.\n",
        "\n",
        "* The `Handle` class is a smart pointer to pointer. The inputs are all stored into handles, so that we could change the quotes and curves used if we wanted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Oq8kgRlxBumA"
      },
      "outputs": [],
      "source": [
        "process = ql.BlackScholesProcess(ql.QuoteHandle(u),\n",
        "                                 ql.YieldTermStructureHandle(riskFreeCurve),\n",
        "                                 ql.BlackVolTermStructureHandle(volatility))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DCd4f0FBumA"
      },
      "source": [
        "After having the process, we can finally use it to build the engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MWOzVSscBumA"
      },
      "outputs": [],
      "source": [
        "engine = ql.AnalyticEuropeanEngine(process)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSK2y5P_BumA"
      },
      "source": [
        "After having the engine, we can set it to the option and evaluate the latter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_5oT4c0sBumA"
      },
      "outputs": [],
      "source": [
        "option.setPricingEngine(engine)\n",
        "print(option.NPV())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB6MDLFOBumA"
      },
      "source": [
        "##### Market changes\n",
        "As mentioned before, market data are stored in `Quote` instances and thus can notify the option when any of them changes. We don’t have to do anything explicitly to tell the option to recalculate: once we set a new value to the underlying, we can simply ask the option for its NPV again and we’ll get the updated value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tgdf5fpsBumA",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "u.setValue(105.0)\n",
        "r.setValue(0.006)\n",
        "print(option.NPV())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41wszhAWBumB"
      },
      "source": [
        "2. Specify the calendar and the day counting convention:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J9N5esj0BumB"
      },
      "outputs": [],
      "source": [
        "calendar = ql.UnitedStates(ql.UnitedStates.NYSE)\n",
        "day_counter = ql.ActualActual(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K35fW9mrBumB"
      },
      "source": [
        "Remarks:\n",
        "* The day counting convention determines the way interest accrues over time for various financial instruments, such as bonds. The `actual/actual` convention means that we use the actual number of elapsed days and the actual number of days in a year – 365 or 366. There are many other conventions such as `actual/365 fixed`, `actual/360`, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkM5FvtoBumB"
      },
      "source": [
        "3. Specify the valuation date and the expiry date of the option:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a6GQxYQpBumB"
      },
      "outputs": [],
      "source": [
        "valuation_date = ql.Date(1, 1, 2018)\n",
        "expiry_date =  ql.Date(1, 1, 2019)\n",
        "ql.Settings.instance().evaluationDate = valuation_date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Mn2u0aBumC"
      },
      "source": [
        "4. Define the option type (call/put), type of exercise and the payoff:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D0SPS8ivBumC"
      },
      "outputs": [],
      "source": [
        "if OPTION_TYPE == 'call':\n",
        "    option_type_ql = ql.Option.Call\n",
        "elif OPTION_TYPE == 'put':\n",
        "    option_type_ql = ql.Option.Put\n",
        "\n",
        "exercise = ql.AmericanExercise(valuation_date, expiry_date)\n",
        "payoff = ql.PlainVanillaPayoff(option_type_ql, K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rns9RJfSBumC"
      },
      "source": [
        "5. Prepare the market-related data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PSc0htngBumC"
      },
      "outputs": [],
      "source": [
        "# wrap the values in quotes so that the values can be changed and the changes are registered in the instrument\n",
        "u = ql.SimpleQuote(S_0)\n",
        "r = ql.SimpleQuote(0.05)\n",
        "sigma = ql.SimpleQuote(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW-ciU1eBumC"
      },
      "source": [
        "6. Specify the market-related curves:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GiiRgNCMBumC"
      },
      "outputs": [],
      "source": [
        "underlying = ql.QuoteHandle(u)\n",
        "# volatility, which is constant as per our assumptions\n",
        "volatility = ql.BlackConstantVol(0, calendar,\n",
        "                                 ql.QuoteHandle(sigma),\n",
        "                                 day_counter)\n",
        "\n",
        "# the risk-free rate, which is also constant over time\n",
        "risk_free_rate = ql.FlatForward(0, calendar,\n",
        "                                ql.QuoteHandle(r),\n",
        "                                day_counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-4JN-2-DBumC"
      },
      "outputs": [],
      "source": [
        "# volatility = ql.BlackConstantVol(valuation_date, calendar, sigma, day_counter)\n",
        "# risk_free_rate = ql.FlatForward(valuation_date, r, day_counter)\n",
        "\n",
        "# `TARGET` is a calendar that contains information on which days are holidays\n",
        "# the price of the underlying instrument\n",
        "underlying = ql.QuoteHandle(u)\n",
        "# volatility, which is constant as per our assumptions\n",
        "volatility = ql.BlackConstantVol(0, ql.TARGET(),\n",
        "                                 ql.QuoteHandle(sigma),\n",
        "                                 day_counter)\n",
        "\n",
        "# the risk-free rate, which is also constant over time\n",
        "risk_free_rate = ql.FlatForward(0, ql.TARGET(),\n",
        "                                ql.QuoteHandle(r),\n",
        "                                day_counter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOXlI5ViBumD"
      },
      "source": [
        "7. Plug in the market-related data into the BS process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VqxZjgfwBumD"
      },
      "outputs": [],
      "source": [
        "bs_process = ql.BlackScholesProcess(\n",
        "    underlying,\n",
        "    ql.YieldTermStructureHandle(risk_free_rate),\n",
        "    ql.BlackVolTermStructureHandle(volatility),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INHd1tvxBumD"
      },
      "source": [
        "8. Instantiate the Monte Carlo engine for the American options:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_lnT6K5uBumD"
      },
      "outputs": [],
      "source": [
        "engine = ql.MCAmericanEngine(bs_process, 'PseudoRandom', timeSteps=N, # the number of time steps for discretization\n",
        "                             polynomOrder=POLY_DEGREE,  # the degree/order of the polynomial in the LSMC algorithm\n",
        "                             seedCalibration=R_SEED,\n",
        "                             requiredSamples=N_SIMS) # the desired number of simulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m37X0BV5BumD"
      },
      "source": [
        "9. Instantiate the `option` object and set its pricing engine:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zLza9u5QBumD"
      },
      "outputs": [],
      "source": [
        "option = ql.VanillaOption(payoff, exercise)\n",
        "option.setPricingEngine(engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipa_yHTcBumD"
      },
      "source": [
        "10. Calculate the option premium:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bo_ee-9tBumD"
      },
      "outputs": [],
      "source": [
        "option_premium_ql = option.NPV()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ej3J8FIqBumD"
      },
      "outputs": [],
      "source": [
        "print(f'The value of the American {OPTION_TYPE} option is: {option_premium_ql:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPgyp1CKBumD"
      },
      "source": [
        "Summary:\n",
        "1. Since we wanted to compare the results we obtained here with those in the previous recipes, we used the same problem setup as we did there. For brevity, we will not look at all the code here, but we should run Step 2 from the previous recipe.\n",
        "2. In Step 2, we specified the calendar and the day-counting convention.\n",
        "3. In Step 3, we selected two dates – valuation and expiry – as we are interested in pricing an option that expires in a year. It is important to set `ql.Settings.instance().evaluationDate` to the considered evaluation date to make sure the calculations are performed correctly. In this case, the dates only determine the passage of time, meaning that the option expires within a year. We would get the same results (with some margin of error due to the random component of the simulations) using different dates with the same interval between them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sabYUeDuBumE"
      },
      "outputs": [],
      "source": [
        "# We can check the time to expiry (in years) by running the following code:\n",
        "T = day_counter.yearFraction(valuation_date, expiry_date)\n",
        "print(f'Time to expiry in years: {T}')\n",
        "# Time to expiry in years: 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8jrw1UjBumE"
      },
      "source": [
        "4. Next, we defined the option type (call/put), the type of exercise (European, American, or Bermudan), and the payoff (Vanilla). In Step 5, we prepared the market data. We wrapped the values in quotes (`ql.SimpleQuote`) so that the values can be changed and the changes are registered in the instrument. This is important for calculating Greeks in the There's more section.\n",
        "\n",
        "5. In Step 6, we defined the relevant curves. In this step, we specified the three important components of the **Black-Scholes (BS)** process, which are:\n",
        "    * The price of the underlying instrument\n",
        "    * Volatility, which is constant as per our assumptions\n",
        "    * The risk-free rate, which is also constant over time\n",
        "    \n",
        "   We passed all these objects to the Black-Scholes process (`ql.BlackScholesProcess`), which we defined in Step 7. Then, we passed the process object into the special engine used for pricing American options using Monte Carlo simulations (there are many predefined engines for different types of options and pricing methods). At this point, we provided the desired number of simulations, the number of time steps for discretization, and the degree/order of the polynomial in the LSMC algorithm.\n",
        "\n",
        "6. In Step 9, we created an instance of `ql.VanillaOption` by providing previously defined types of payoff and exercise. We also set the pricing engine using the `setPricingEngine` method.\n",
        "\n",
        "7. Finally, we obtained the price of the option using the `NPV` method.\n",
        "\n",
        "By doing this, we can see that the option premium we obtained using QuantLib is very similar to the one we calculated previously, which further validates our results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2diBvDRdBumE"
      },
      "source": [
        "### There's more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVTctq7PBumE"
      },
      "source": [
        "QuantLib also allows us to use variance reduction techniques such as antithetic values or **control variates**.\n",
        "\n",
        "Now that we have completed the preceding steps, we can calculate Greeks. Greeks (from the letters of the Greek alphabet) represent the sensitivity of the price of derivatives (for example, the option premium) to a change in one of the underlying parameters (such as the price of the underlying asset, time to expiry, volatility, the interest rate, and so on). When there is an analytical formula available for the Greeks (when the QuantlLib engine is using analytical formulas), we could just access it by running, for example, `option.delta()`. However, in cases such as valuations using binomial trees or simulations, there is no analytical formula and we would receive an error (`RuntimeError: delta not provided`). This does not mean that it is impossible to calculate it, but we need to employ numerical differentiation and calculate it ourselves. In this example, we will only extract the delta. Therefore, the relevant two-sided formula is:\n",
        "\n",
        "<center>$\\Delta=\\frac{P(S_0+h)-P(S_0-h)}{2h}$</center>\n",
        "\n",
        "Here, *P(S)* is the price of the instrument given the underlying's price *S*; *h* is a very small increment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2CWEqzvvBumE"
      },
      "outputs": [],
      "source": [
        "# calculate the delta\n",
        "u_0 = u.value() # original value\n",
        "h = 0.01\n",
        "\n",
        "u.setValue(u_0 + h)\n",
        "P_plus_h = option.NPV()\n",
        "\n",
        "u.setValue(u_0 - h)\n",
        "P_minus_h = option.NPV()\n",
        "\n",
        "u.setValue(u_0) # set back to the original value\n",
        "\n",
        "delta = (P_plus_h - P_minus_h) / (2 * h)\n",
        "\n",
        "print(f'Delta of the option: {delta:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mxn0OOeBumE"
      },
      "source": [
        "The simplest interpretation of the delta is that the option's delta being equal to -1.25 indicates that, if the underlying stock increases in price by \\\\$1 per share, the option on it will decrease by \\\\$1.25 per share; otherwise, everything will be equal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMRdXo6pBumE"
      },
      "source": [
        "## Estimating Value-at-risk using Monte Carlo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72BYp0dLBumE"
      },
      "source": [
        "**Value-at-risk** is a very important financial metric that measures the risk associated with a position, portfolio, and so on. It is commonly abbreviated to VaR, not to be confused with Vector Autoregression. VaR reports the worst expected loss – at a given level of confidence – over a certain horizon under normal market conditions. The easiest way to understand it is by looking at an example. Let's say that the 1-day 95% VaR of our portfolio is \\\\$100. This means that 95% of the time (under normal market conditions), we will not lose more than \\\\$100 by holding our portfolio over one day.\n",
        "\n",
        "It is common to present the loss given by VaR as a positive (absolute) value. That is why in this example, a VaR of \\\\$100 means losing no more than \\\\$100.\n",
        "\n",
        "\n",
        "There are several ways to calculate VaR, some of which are:\n",
        "\n",
        "* Parametric Approach (Variance-Covariance)\n",
        "* Historical Simulation Approach\n",
        "* Monte Carlo simulations\n",
        "\n",
        "In this recipe, we only consider the last method. We assume that we are holding a portfolio consisting of two assets (Facebook and Google) and that we want to calculate a 1-day value-at-risk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2zDw6VNBumE"
      },
      "source": [
        "### How to do it..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAiu6U-qBumE"
      },
      "source": [
        "1. Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oVIxMLoaBumF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LqMYHSy9BumF"
      },
      "outputs": [],
      "source": [
        "# set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypKdX2VFBumF"
      },
      "source": [
        "2. Define the parameters that will be used for this exercise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LuMObkAoBumF"
      },
      "outputs": [],
      "source": [
        "RISKY_ASSETS = ['GOOG', 'META']\n",
        "SHARES = [5, 5] # the number of shares we have in our portfolio\n",
        "START_DATE = '2018-01-01'\n",
        "END_DATE = '2018-12-31'\n",
        "T = 1\n",
        "N_SIMS = 10 ** 5 # the number of simulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGBiLMGVBumF"
      },
      "source": [
        "3. Download data from Yahoo Finance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "If9wzj_VBumF",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# downloaded the daily stock prices of Google and Facebook\n",
        "df = yf.download(RISKY_ASSETS, start=START_DATE,\n",
        "                 end=END_DATE)\n",
        "print(f'Downloaded {df.shape[0]} rows of data.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n6Z1CnGcBumF"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LCB3FX7BumF"
      },
      "source": [
        "4. Calculate daily returns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uKKpsO6PBumF",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# extract the adjusted close prices\n",
        "adj_close = df['Close']\n",
        "# converte adjusted close prices into simple returns\n",
        "returns = adj_close.pct_change().dropna()\n",
        "plot_title = f'{\" vs. \".join(RISKY_ASSETS)} returns: {START_DATE} - {END_DATE}'\n",
        "returns.plot(title=plot_title)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'Correlation between returns: {returns.corr().values[0,1]:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVn5woGHBumF"
      },
      "source": [
        "Notes:\n",
        "* `string.join(iterable)`\n",
        "    * The `join()` method joins all items in an iterable into a single string. Call this method on a string you want to use as a delimiter like comma, space etc.\n",
        "    * `iterable`: any iterable (like list, tuple, dictionary etc.) whose items are strings\n",
        "    * The method returns the string obtained by concatenating the items of an iterable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-hpoqFVoBumF"
      },
      "outputs": [],
      "source": [
        "# example=[1,2] # items are ints\n",
        "# \"+\".join(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X0qw1UclBumG"
      },
      "outputs": [],
      "source": [
        "example=['1','2'] # items are strings\n",
        "\"+\".join(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3S-T8HwBumG"
      },
      "source": [
        "5. Calculate the covariance matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s3aXYUEmBumG",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "cov_mat = returns.cov()\n",
        "cov_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC22o8QRBumG"
      },
      "source": [
        "Remarks:\n",
        "* The Monte Carlo approach to determining the price of an asset employs random variables drawn from the Standard Normal distribution. For the case of calculating portfolio VaR, we need to account for the fact that the assets in our portfolio may be correlated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK_bVAAzBumG"
      },
      "source": [
        "6. Perform the Cholesky decomposition of the covariance matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MoDQB1rQBumG"
      },
      "outputs": [],
      "source": [
        "chol_mat = np.linalg.cholesky(cov_mat)\n",
        "chol_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5efQGiIlBumG"
      },
      "source": [
        "Notes:\n",
        "* `numpy.linalg.cholesky(a)`\n",
        "    * Cholesky decomposition.\n",
        "    * `a` : *(..., M, M) array_like*. Hermitian (symmetric if all elements are real), positive-definite input matrix.\n",
        "    * Return the Cholesky decomposition, where `L` is lower-triangular."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cJP7ZqvFBumH"
      },
      "outputs": [],
      "source": [
        "# np.linalg.cholesky\n",
        "a = np.array([[4, 12, -16],\n",
        "              [12, 37, -43],\n",
        "              [-16, -43, 98]])\n",
        "L=np.linalg.cholesky(a)\n",
        "print(L)\n",
        "print(np.matmul(L,L.T))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7usfEdGoBumH"
      },
      "source": [
        "7. Draw correlated random numbers from Standard Normal distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jpUig7UkBumH"
      },
      "outputs": [],
      "source": [
        "rv = np.random.normal(size=(N_SIMS, len(RISKY_ASSETS)))\n",
        "# multiply the resulting matrix by the matrix of random variables so that add correlation to the generated random variables\n",
        "correlated_rv = np.transpose(np.matmul(chol_mat, np.transpose(rv)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpfhQe3oBumH"
      },
      "source": [
        "8. Define metrics used for simulations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1Abd6gzqBumH"
      },
      "outputs": [],
      "source": [
        "r = np.mean(returns, axis=0).values # the historical averages of the asset return\n",
        "sigma = np.std(returns, axis=0).values # the historical standard deviations of the asset return\n",
        "S_0 = adj_close.values[-1, :] # the last known stock prices\n",
        "P_0 = np.sum(SHARES * S_0) # the initial portfolio value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4kge1EpBumH"
      },
      "source": [
        "9. Calculate the terminal price of the considered stocks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UTHE1y_iBumH"
      },
      "outputs": [],
      "source": [
        "# calculate possible 1-day-ahead stock prices for both assets\n",
        "S_T = S_0 * np.exp((r - 0.5 * sigma ** 2) * T + # apply the analytical solution to the Geometric Brownian Motion SDE\n",
        "                   sigma * np.sqrt(T) * correlated_rv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xNzLyryBumH"
      },
      "source": [
        "10. Calculate the terminal portfolio value and calculate the portfolio returns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fUHt4ekZBumH"
      },
      "outputs": [],
      "source": [
        "P_T = np.sum(SHARES * S_T, axis=1) # calculate the possible 1-day-ahead portfolio values\n",
        "P_diff = P_T - P_0 # calculated the portfolio differences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qiVRZ9ZBumI"
      },
      "source": [
        "11. Calculate VaR:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gCpUL4N1BumI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "P_diff_sorted = np.sort(P_diff) # sort the portfolio differences in ascending order\n",
        "percentiles = [0.01, 0.1, 1.]\n",
        "var = np.percentile(P_diff_sorted, percentiles)\n",
        "\n",
        "for x, y in zip(percentiles, var):\n",
        "    print(f'1-day VaR with {100-x}% confidence: {-y:.2f}$') # The X% VaR is simply the (1-X)-th percentile of the sorted portfolio differences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DN3GHaZBumI"
      },
      "source": [
        "Notes:\n",
        "* `numpy.sort(a, axis=- 1)`\n",
        "    * Return a sorted copy of an array.\n",
        "    * `axis` : *int or None, optional* Axis along which to sort. If None, the array is flattened before sorting. The default is -1, which sorts along the last axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5QuCwaXHBumI"
      },
      "outputs": [],
      "source": [
        "# np.sort\n",
        "example = np.array([[1,3],[4,2]])\n",
        "print(example)\n",
        "print(np.sort(example))                # sort along the last axis (along columns)\n",
        "print(np.sort(example, axis=None))     # sort the flattened array\n",
        "print(np.sort(example, axis=0))        # sort along the first axis (along rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5pHQLlXBumI"
      },
      "source": [
        "Notes:\n",
        "* `numpy.percentile(a,q)`\n",
        "    * Compute the q-th percentile of the data.\n",
        "    * `a` : *array_like*. Input array or object that can be converted to an array.\n",
        "    * `q` : *array_like of float*. Percentile or sequence of percentiles to compute, which must be between 0 and 100 inclusive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ALHuYAI8BumI"
      },
      "outputs": [],
      "source": [
        "# percentile\n",
        "example = range(1,100)\n",
        "print(np.percentile(example, 50))\n",
        "print(np.percentile(example, 0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNC7gf8gBumI"
      },
      "source": [
        "Notes:\n",
        "* *Python Iterators*\n",
        "    * An iterator is an object that contains a countable number of values.\n",
        "    * An iterator is an object that can be iterated upon, meaning that you can traverse through all the values.\n",
        "    * Lists, tuples, dictionaries, and sets are all iterable objects. They are iterable containers which you can get an iterator from. The built-in function `iter()` takes an iterable object and returns an iterator.\n",
        "    * Each time we call the next method on the iterator gives us the next element. If there are no more elements, it raises a `StopIteration`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oR2NRjWXBumI"
      },
      "outputs": [],
      "source": [
        "# astr = \"Python\"\n",
        "# example = iter(astr)\n",
        "# print(example)\n",
        "\n",
        "# print(next(example))\n",
        "# print(next(example))\n",
        "# print(next(example))\n",
        "# print(next(example))\n",
        "# print(next(example))\n",
        "# print(next(example))\n",
        "# print(next(example)) # If there are no more elements, it raises a StopIteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hc79RhlcBumI"
      },
      "outputs": [],
      "source": [
        "# there are many functions which consume these iterables\n",
        "print(\",\".join([\"a\", \"b\", \"c\"]))\n",
        "print(\",\".join({\"x\": 1, \"y\": 2})) # join on dictionary: all dictionary keys are joined by default\n",
        "print(list(\"python\"))\n",
        "print(list({\"x\": 1, \"y\": 2}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGCsepppBumJ"
      },
      "source": [
        "Notes:\n",
        "* `zip()`\n",
        "    * The built-in function `zip()` aggregates the elements from multiple iterable objects (lists, tuples, etc.). It is used when iterating multiple list elements in a for loop.\n",
        "    * By passing an iterable object (lists, tuples, etc.) as an argument of `zip()`, multiple elements can be obtained simultaneously in the for loop.\n",
        "    * The result of the `zip()` function is an iterator. An iterator in Python is an object that contains a fixed number of elements and allows you to access each element in an ordered fashion (the next(iterator) function for an iterator). This is more efficient and more general-purpose — compared to creating a list and returning the list as a result. To fix this, you have to convert the iterator object in the iterable you want (e.g. set, list, tuple).\n",
        "    * You can unzip zip object by using the asterisk operator `*`.\n",
        "    * zip creates an object for iterating once over the results. This also means it's exhausted after one iteration. You need to call `zip(a,b)` every time you wish to use it or store the `list(zip(a,b))` result and use that repeatedly instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Uw_NoRrJBumJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# zip()\n",
        "a = [1,2]\n",
        "b = [3,4]\n",
        "c = [3,4,5]\n",
        "\n",
        "example1 = list(zip(a,b))\n",
        "print(example1)\n",
        "\n",
        "# using `*` to unzip\n",
        "a1, b1 = zip(*zip(a,b))\n",
        "print(a1,b1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZNlUBmISBumJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# zip lists of different lengths\n",
        "example2=zip(a,c)\n",
        "print(example2) # zip object\n",
        "print(tuple(example2)) # Python simply ignores the remaining elements of the longer list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ByHvLXIrBumJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "example3 = zip(a,b)\n",
        "print(tuple(example3))\n",
        "#it's exhausted after one iteration\n",
        "print(example3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j5SohvdxBumJ"
      },
      "outputs": [],
      "source": [
        "# display a readable version of the result\n",
        "print(tuple(zip(a,b)))  # use the tuple() function\n",
        "print([x for x in zip(a,b)]) # use list comprehension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eusVZIn4BumJ"
      },
      "source": [
        "12. Present the results on a graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KVb1kkJnBumJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "ax = sns.distplot(P_diff, kde=False) # `kde`: Whether to plot a gaussian kernel density estimate.\n",
        "ax.set_title('''Distribution of possible 1-day changes in portfolio value\n",
        "             1-day 99% VaR''', fontsize=16)\n",
        "ax.axvline(var[2], 0, 10000) # Add a vertical line across the axes\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "733JejlXBumJ"
      },
      "source": [
        "Notes:\n",
        "* Multiple Lines\n",
        "    * Printing strings on multiple lines can make text more readable to humans. With multiple lines, strings can be grouped into clean and orderly text, formatted as a letter, or used to maintain the linebreaks of a poem or song lyrics.\n",
        "    * To create strings that span multiple lines, triple single quotes `'''` or triple double quotes `\"\"\"` are used to enclose the string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nFBk7suDBumJ"
      },
      "outputs": [],
      "source": [
        "print('''\n",
        "Hello\n",
        "World!\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmc7IUZEBumJ"
      },
      "source": [
        "The preceding plot shows the distribution of possible 1-day ahead portfolio values. We present the value-at-risk with the vertical line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0n6uEW5BumK"
      },
      "source": [
        "Summary:\n",
        "\n",
        "1. In Steps 2 to 4, we downloaded the daily stock prices of Google and Facebook, extracted the adjusted close prices, and converted them into simple returns. We also defined a few parameters, such as the number of simulations and the number of shares we have in our portfolio.\n",
        "    \n",
        "    There are two ways to approach VaR calculations:<br>\n",
        "    * **Calculate VaR from prices**: Using the number of shares and the asset prices, we can calculate the worth of the portfolio now and its possible value X days ahead.\n",
        "    * **Calculate VaR from returns**: Using the percentage weights of each asset in the portfolio and the assets' expected returns, we can calculate the expected portfolio return X days ahead. Then, we can express VaR as the dollar amount based on that return and the current portfolio value.\n",
        "\n",
        "2. The Monte Carlo approach to determining the price of an asset employs random variables drawn from the Standard Normal distribution. For the case of calculating portfolio VaR, we need to account for the fact that the assets in our portfolio may be correlated. To do so, in Steps 5 to 7, we calculated the historical covariance matrix, used the Cholesky decomposition on it, and multiplied the resulting matrix by the matrix of random variables. This way, we added correlation to the generated random variables.\n",
        "\n",
        "    * Another possible option for making random variables correlated is to use the **Singular Value Decomposition (SVD)** instead of the Cholesky decomposition. The function we can use for this is `np.linalg.svd`.\n",
        "\n",
        "3. In Step 8, we calculated metrics such as the historical averages of the asset return, the accompanying standard deviations, the last known stock prices, and the initial portfolio value. In Step 9, we applied the analytical solution to the Geometric Brownian Motion SDE and calculated possible 1-day-ahead stock prices for both assets.\n",
        "\n",
        "4. To calculate the portfolio VaR, we calculated the possible 1-day-ahead portfolio values and the accompanying differences $(P_T-P_0)$ and sorted them in ascending order. The X% VaR is simply the (1-X)-th percentile of the sorted portfolio differences.\n",
        "\n",
        "   * Banks frequently calculate the 1-day and 10-day VaR. To arrive at the latter, they can simulate the value of their assets over a 10-day interval using 1-day steps (discretization). However, they can also calculate the 1-day VaR and multiply it by the square root of 10. This might be beneficial for the bank if it leads to lower capital requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htu79-bZBumK"
      },
      "source": [
        "### There's more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ38QHP0BumK"
      },
      "source": [
        "Calculating VaR using different approaches has its drawbacks, some of which are:\n",
        "\n",
        "* Assuming a parametric distribution (variance-covariance approach).\n",
        "* Not capturing enough tail risk.\n",
        "* Not considering the so-called Black Swan events (unless they are already in the historical sample).\n",
        "* Historical VaR can be slow to adapt to new market conditions.\n",
        "* The Historical Simulation Approach assumes that past returns are sufficient to evaluate future risk (connects to the previous points).\n",
        "\n",
        "Another general drawback of VaR is that it does not contain information about the size of the potential loss when it exceeds the threshold given by VaR. This is when **Expected Shortfall** (also known as conditional VaR or expected tail loss) comes into play. It simply states what the expected loss is in the worst X% of scenarios.\n",
        "\n",
        "There are many ways to calculate the Expected Shortfall, but here, we present the one that is easily connected to the VaR and can be estimated using Monte Carlo.\n",
        "\n",
        "Following on from the example of a two-asset portfolio, we would like to know the following: if the loss exceeds the VaR, how big will it be? To obtain that number, we need to filter out all losses that are higher than the value given by VaR and calculate their expected value by taking the average."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q3kSepmtBumK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "var = np.percentile(P_diff_sorted, 5) # 95% VaR\n",
        "expected_shortfall = P_diff_sorted[P_diff_sorted<=var].mean()\n",
        "\n",
        "print(f'The 1-day 95% VaR is {-var:.2f}$, and the accompanying Expected Shortfall is {-expected_shortfall:.2f}$.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxOFKb1RBumK"
      },
      "source": [
        "Please bear in mind that, for Expected Shortfall, we only use a small fraction of all the simulations that were used to obtain the VaR. That is why, in order to have reasonable results for the Expected Shortfall, the overall sample must be large enough.\n",
        "\n",
        "The 1-day 95% VaR is \\\\$4.48, while the accompanying Expected Shortfall is \\\\$5.27. We can interpret these results as follows: if the loss exceeds the 95% VaR, we can expect to lose \\\\$5.27 by holding our portfolio for 1 day."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQhop4qHBumK"
      },
      "source": [
        "References:<br>\n",
        "https://www.interviewqs.com/blog/intro-monte-carlo<br>\n",
        "https://pythonforfinance.net/2016/11/28/monte-carlo-simulation-in-python/#more-15561<br>\n",
        "Price options using Monte Carlo Simulations<br>\n",
        "http://www.codeandfinance.com/pricing-options-monte-carlo.html<br>\n",
        "https://www.quantopia.net/quantlib-setting-up-quantlib-python-and-pricing-an-option/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "396px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}